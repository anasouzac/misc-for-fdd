{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e933ab8d",
   "metadata": {},
   "source": [
    "## Referência"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5571eea6",
   "metadata": {},
   "source": [
    "Parte do presente script (classe PCA) usou como base o código apresentado na aula abaixo:\n",
    "\n",
    "https://www.kaggle.com/code/afrniomelo/epv-peq-aula-2-detec-o-de-falhas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c250c29b",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0fcecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import Counter\n",
    "from datetime import timedelta\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support , roc_auc_score, auc, precision_score\n",
    "from timeit import default_timer as timer\n",
    "from scipy.stats import f, norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7ca32c",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d0bb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA():\n",
    "   \n",
    "    # ---------------------------------------------------------------------------\n",
    "    # Método construtor\n",
    "    # Função que será chamada toda vez que um objeto PCA for inicializado\n",
    "    # O modelo selecionará quantos PCs forem necessários para cumprir o % de variabilidade explicada especificado em a\n",
    "\n",
    "    def __init__ (self, a=0.9):\n",
    "\n",
    "        # se 0<=a<1,  'a' indica a fraçao de variancia explicada desejada\n",
    "        # se a>=1,    'a' indica o numero de componentes desejado\n",
    "        self.a = a\n",
    "   \n",
    "    # ---------------------------------------------------------------------------\n",
    "    # Função para treino do modelo\n",
    "    # X são os dados de treino\n",
    "    \n",
    "    def fit(self, X, conf_Q=0.99, conf_T2=0.99, plot=True):\n",
    "    \n",
    "        # guardando médias e desvios-padrão do treino (de cada coluna)\n",
    "        self.mu_train = X.mean(axis=0)\n",
    "        self.std_train = X.std(axis=0)        \n",
    "       \n",
    "        # normalizando dados de treino\n",
    "        X = np.array(((X - self.mu_train)/self.std_train))\n",
    "       \n",
    "        # calculando a matriz de covariâncias dos dados\n",
    "        Cx = np.cov(X, rowvar=False)\n",
    "        \n",
    "        # aplicando decomposição em autovalores e autovetores\n",
    "        self.L, self.P = np.linalg.eig(Cx)\n",
    "        \n",
    "        # frações da variância explicada\n",
    "        fv = self.L/np.sum(self.L)\n",
    "        \n",
    "        # frações da variância explicada acumuladas\n",
    "        fva = np.cumsum(self.L)/sum(self.L)\n",
    "       \n",
    "        # definindo número de componentes\n",
    "        if (self.a>0 and self.a<1):\n",
    "            self.a = np.where(fva>self.a)[0][0]+1 \n",
    "            \n",
    "        # calculando limites de detecção\n",
    "\n",
    "        # limite da estatística T^2\n",
    "        F = f.ppf(conf_T2, self.a, X.shape[0]-self.a)\n",
    "        self.T2_lim = ((self.a*(X.shape[0]**2-1))/(X.shape[0]*(X.shape[0]-self.a)))*F\n",
    "        print(\"T2_lim: \", self.T2_lim)\n",
    "        \n",
    "        # limite da estatística Q\n",
    "        theta = [np.sum(self.L[self.a:]**(i)) for i in (1,2,3)]\n",
    "        ho = 1-((2*theta[0]*theta[2])/(3*(theta[1]**2)))\n",
    "        nalpha = norm.ppf(conf_Q)\n",
    "        self.Q_lim = (theta[0]*(((nalpha*np.sqrt(2*theta[1]*ho**2))/theta[0])+1+\n",
    "                                ((theta[1]*ho*(ho-1))/theta[0]**2))**(1/ho))\n",
    "        print(\"Q_lim: \", self.Q_lim)\n",
    "        \n",
    "        # plotando variâncias explicadas\n",
    "        if plot:\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.bar(np.arange(len(fv)),fv)\n",
    "            ax.plot(np.arange(len(fv)),fva)\n",
    "            ax.set_xlabel('Número de componentes')\n",
    "            ax.set_ylabel('Variância dos dados')\n",
    "            ax.set_title('PCA - Variância Explicada');\n",
    "\n",
    "    # ---------------------------------------------------------------------------\n",
    "    # Função para teste do modelo\n",
    "            \n",
    "    def predict(self, X):\n",
    "            \n",
    "        # normalizando dados de teste (usando os parâmetros do treino!)\n",
    "        X = np.array((X - self.mu_train)/self.std_train)\n",
    "\n",
    "        # calculando estatística T^2\n",
    "        T = X@self.P[:,:self.a]\n",
    "        self.T2 = np.array([T[i,:]@np.linalg.inv(np.diag(self.L[:self.a]))@T[i,:].T for i in range(X.shape[0])])\n",
    "\n",
    "        # calculando estatística Q\n",
    "        e = X - X@self.P[:,:self.a]@self.P[:,:self.a].T\n",
    "        self.Q  = np.array([e[i,:]@e[i,:].T for i in range(X.shape[0])])\n",
    "        \n",
    "        # calculando contribuições para Q\n",
    "        self.c = np.absolute(X*e) \n",
    "                \n",
    "    # ---------------------------------------------------------------------------\n",
    "    # Função para plotar cartas de controle\n",
    "    # Eixo y contém as estatísticas e eixo x contém a quantidade de amostras\n",
    "    \n",
    "    def plot_control_charts(self, fault = None):\n",
    "     \n",
    "        fig, ax = plt.subplots(1,2, figsize=(15,3))\n",
    "        \n",
    "        ax[0].semilogy(self.T2,'.')\n",
    "        ax[0].axhline(self.T2_lim,ls='--',c='r');\n",
    "        ax[0].set_title('Carta de Controle $T^2$')\n",
    "        ax[0].set_xlabel('Samples')\n",
    "        ax[0].set_ylabel('$T^2$')\n",
    "        \n",
    "        ax[1].semilogy(self.Q,'.')\n",
    "        ax[1].axhline(self.Q_lim,ls='--',c='r')\n",
    "        ax[1].set_title('Carta de Controle Q')\n",
    "        ax[1].set_xlabel('Samples')\n",
    "        ax[1].set_ylabel('$Q$')\n",
    " \n",
    "        if fault is not None:\n",
    "            ax[0].axvline(fault, c='w')\n",
    "            ax[1].axvline(fault, c='w')\n",
    "\n",
    "    # ---------------------------------------------------------------------------\n",
    "    # Função para plotar mapas de contribuição\n",
    "            \n",
    "    def plot_contributions(self, fault=None, index=None, columns=None):\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(20, 6))\n",
    "        \n",
    "        c = pd.DataFrame(self.c, index=index, columns=columns)\n",
    "    \n",
    "        sns.heatmap(c, ax=ax, yticklabels=int(self.c.shape[0]/10), cmap = plt.cm.Blues)\n",
    "        \n",
    "        ax.set_title('Contribuições parciais para Q')\n",
    "        \n",
    "        if fault is not None:\n",
    "            ax.axhline(y=c.index[fault], ls='--', c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80923024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_real, y_pred, conf_matrix, STATUS, multi_problem):\n",
    "    \n",
    "    # Classificação multiclass\n",
    "    if (multi_problem):\n",
    "    \n",
    "        cm_values = conf_matrix.values\n",
    "    \n",
    "        # Cálculo dos FP, FN e TP para cada classe\n",
    "        tp = np.zeros((len(cm_values),1))\n",
    "        tn = np.zeros((len(cm_values),1))\n",
    "        fp = np.zeros((len(cm_values),1))\n",
    "        fn = np.zeros((len(cm_values),1))\n",
    "        acc = np.zeros((len(cm_values),1))\n",
    "\n",
    "        for i in range(0, len(cm_values)):\n",
    "\n",
    "            tp[i] = cm_values[i,i]\n",
    "            fp[i] = cm_values[:,i].sum() - cm_values[i,i]\n",
    "            fn[i] = cm_values[i,:].sum() - cm_values[i,i]\n",
    "            tn[i] = len(y_real) - tp[i] - fp[i] - fn[i]\n",
    "            acc[i] = (len(y_real) - (cm_values[i,:].sum() + cm_values[:,i].sum() - 2*cm_values[i,i]))/len(y_real)\n",
    "\n",
    "        # Cálculo das métricas Precision, Recall e F-Score para cada classe\n",
    "        try:\n",
    "            metricas = precision_recall_fscore_support(y_real.argmax(axis=1), y_pred.argmax(axis=1), zero_division=0)\n",
    "        except:\n",
    "            metricas = precision_recall_fscore_support(y_real, y_pred, zero_division=0)\n",
    "\n",
    "        # Arranjo do dataframe e inclusão de outras métricas\n",
    "        metricas_df = pd.DataFrame(list(metricas))\n",
    "        metricas_df = metricas_df.transpose()\n",
    "\n",
    "        metricas_df.columns = ['Precision', 'Recall', 'F-score(a=1)', 'Total']\n",
    "        metricas_df['Accuracy'] = acc\n",
    "        metricas_df['Class'] = STATUS\n",
    "        metricas_df['Total'] = metricas_df['Total'].astype(int)\n",
    "\n",
    "        metricas_df['TP'] = tp.astype(int)\n",
    "        metricas_df['TN'] = tn.astype(int)\n",
    "        metricas_df['FP'] = fp.astype(int)\n",
    "        metricas_df['FN'] = fn.astype(int)\n",
    "\n",
    "        metricas_df['Specificity'] = (metricas_df['TN']/(metricas_df['TN'] + metricas_df['FP']))\n",
    "        metricas_df['FPR(FAR)'] = (metricas_df['FP']/(metricas_df['FP'] + metricas_df['TN']))\n",
    "        metricas_df['F-score(a=0.5)'] =\\\n",
    "            (1.5*metricas_df['Precision']*metricas_df['Recall'])/((0.5*metricas_df['Precision']) + metricas_df['Recall'])\n",
    "        metricas_df['F-score(a=2)'] =\\\n",
    "            (3*metricas_df['Precision']*metricas_df['Recall'])/((2*metricas_df['Precision']) + metricas_df['Recall'])\n",
    "        metricas_df['F-score(a=0.5)'].fillna(0, inplace=True)\n",
    "        metricas_df['F-score(a=2)'].fillna(0, inplace=True)\n",
    "\n",
    "        metricas_df = metricas_df.set_index('Class')\n",
    "        metricas_df = metricas_df[['Precision', 'Recall', 'F-score(a=1)', 'F-score(a=0.5)', 'F-score(a=2)', \\\n",
    "                                   'Specificity', 'Accuracy', 'FPR(FAR)', 'TP', 'TN', 'FP', 'FN', 'Total']]\n",
    "    \n",
    "    # Classificação binária\n",
    "    else:\n",
    "        \n",
    "        try:\n",
    "            tn, fp, fn, tp = confusion_matrix(y_real.argmax(axis=1), y_pred.argmax(axis=1)).ravel()\n",
    "        except:\n",
    "            tn, fp, fn, tp = confusion_matrix(y_real, y_pred).ravel()\n",
    "        \n",
    "        recall = tp/(tp+fn)\n",
    "        precision = tp/(tp+fp)\n",
    "        f1_score = 2*recall*precision/(recall+precision)\n",
    "        f2_score = 3*recall*precision/((2*precision)+recall)\n",
    "        f05_score = 1.5*recall*precision/((0.5*precision)+recall)\n",
    "        accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "        specificity = tn/(fp+tn)\n",
    "        fpr = fp/(fp+tn)\n",
    "        \n",
    "        metricas_df = pd.DataFrame([precision, recall, f1_score, f05_score, f2_score, specificity, accuracy, fpr, tp, \\\n",
    "                                    tn, fp, fn]).T\n",
    "        metricas_df.columns = ['Precision', 'Recall', 'F-score(a=1)', 'F-score(a=0.5)', 'F-score(a=2)', \\\n",
    "                               'Specificity', 'Accuracy', 'FPR(FAR)', 'TP', 'TN', 'FP', 'FN']\n",
    "\n",
    "    return metricas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99ac163",
   "metadata": {},
   "source": [
    "## Fixando a seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f88c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed value\n",
    "# Mesma seed utilizada no script que gerou o melhor modelo da CNN\n",
    "seed_value = 53771\n",
    "print(seed_value)\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e3baeb",
   "metadata": {},
   "source": [
    "## 1. Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4e23ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"/home/lcap/Desktop/workspace/data/bomba/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1930a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path + \"banco_labeling-v1.csv\", sep=';')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cff96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe89956",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_data = data[['Time']].copy()\n",
    "data = data.drop(['Time'], axis=1)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bacb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = pd.read_csv(data_path + \"banco_labeling_params-v1.csv\", sep=';')\n",
    "params.drop(['status_init', 'status_end'], 1, inplace=True)\n",
    "params.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783aa49b",
   "metadata": {},
   "source": [
    "### Divisão dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196d4b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# O PCA é treinado para reconhecer apenas a operação normal\n",
    "# A divisão abaixo é igual à divisão utilizada no script que gerou o melhor modelo da CNN\n",
    "\n",
    "x_data = data.loc[:1212560,:].copy()\n",
    "x_data = x_data[x_data['rotulos_multi'] == 0].copy()\n",
    "y_data = x_data[['rotulos_multi']].copy()\n",
    "x_data.drop(['rotulos_multi', 'rotulos_bin'], axis=1, inplace=True)\n",
    "\n",
    "# O banco de teste possui tanto dados normais quanto de falha\n",
    "\n",
    "x_test = data.loc[1212560:,:].copy()\n",
    "y_test = x_test[['rotulos_multi']].copy()\n",
    "# x_test.drop(['rotulos_multi', 'rotulos_bin'], axis=1, inplace=True)\n",
    "\n",
    "print(\"\\nTREINO\")\n",
    "print(\"X: \", np.shape(x_data))\n",
    "print(\"Y: \", np.shape(y_data))\n",
    "print(\"Status:\", Counter(y_data['rotulos_multi']))\n",
    "\n",
    "print(\"\\nTESTE\")\n",
    "print(\"X: \", np.shape(x_test))\n",
    "print(\"Y: \", np.shape(y_test))\n",
    "print(\"Status:\", Counter(y_test['rotulos_multi']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896eb699",
   "metadata": {},
   "source": [
    "## 2. Aplicação do PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0056275c",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f020966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia o objeto PCA\n",
    "pca = PCA(a=0.9)\n",
    "\n",
    "# Treina o modelo PCA\n",
    "pca.fit(x_data)\n",
    "\n",
    "print(\"\\nPCs: \", pca.a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dabe12b",
   "metadata": {},
   "source": [
    "### Teste - Falhas e operação normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7789280b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Aplicação do PCA\n",
    "\n",
    "fault_id = y_test['rotulos_multi'].unique()#[1:]\n",
    "\n",
    "# Dataframe para armazenar estatísticas calculadas\n",
    "pca_stats = pd.DataFrame(np.zeros((len(fault_id),3)), columns=['fault', 'T2', 'Q'])\n",
    "\n",
    "# Dataframe para armazenar o resultado do PCA de cada instância\n",
    "pca_results_final = pd.DataFrame(columns=['T2', 'Q', 'fault'])\n",
    "\n",
    "data_to_pca = x_test.copy()\n",
    "data_to_pca.rename(columns={'rotulos_multi': 'STATUS'}, inplace=True)\n",
    "\n",
    "i=0\n",
    "\n",
    "for fault in fault_id:\n",
    "    \n",
    "    print(\"\\n-------------------------------------------------------------------------------\")\n",
    "    df_test = data_to_pca.query(\"STATUS == \" + str(fault)).copy()\n",
    "    df_test.drop(['STATUS', 'rotulos_bin'], 1, inplace=True)\n",
    "    \n",
    "    pca.predict(df_test)\n",
    "    \n",
    "    print(f'Taxas de detecção de falhas - ID({fault})')\n",
    "    \n",
    "    print(f'\\nT2: {(pca.T2>pca.T2_lim).sum()/pca.T2.shape[0]}')\n",
    "    print(f'Q: {(pca.Q>pca.Q_lim).sum()/pca.Q.shape[0]}')\n",
    "    \n",
    "    pca_stats['fault'].iloc[i] = fault\n",
    "    pca_stats['Q'].iloc[i] = (pca.Q>pca.Q_lim).sum()/pca.Q.shape[0]\n",
    "    pca_stats['T2'].iloc[i] = (pca.T2>pca.T2_lim).sum()/pca.T2.shape[0]\n",
    "    \n",
    "    pca_results_parcial = pd.DataFrame(columns=['T2', 'Q'])\n",
    "    pca_results_parcial['T2'] = pca.T2\n",
    "    pca_results_parcial['Q'] = pca.Q\n",
    "    pca_results_parcial['fault'] = fault\n",
    "    pca_results_final = pca_results_final.append(pca_results_parcial)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "    pca.plot_control_charts()\n",
    "    plt.suptitle(f'ID({fault})');\n",
    "\n",
    "    pca.plot_contributions(columns=df_test.columns)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1ab9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930d8df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_results_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed18488",
   "metadata": {},
   "source": [
    "### Pré-falha 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffef4a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_fault17 = x_test.loc[1213608:1218929,:].copy()\n",
    "pre_fault17 = pre_fault17.reset_index().drop(['index'], axis=1)\n",
    "\n",
    "plt.plot(pre_fault17['rotulos_multi']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df70396",
   "metadata": {},
   "outputs": [],
   "source": [
    "fault = 17\n",
    "\n",
    "data_to_pca = pre_fault17.copy()\n",
    "data_to_pca.rename(columns={'rotulos_multi': 'STATUS'}, inplace=True)\n",
    "\n",
    "df_test = data_to_pca.copy()\n",
    "df_test.drop(['STATUS', 'rotulos_bin'], 1, inplace=True)\n",
    "\n",
    "pca.predict(df_test)\n",
    "\n",
    "print(f'Taxas de detecção de falhas + pré-falha - ID({fault})')\n",
    "\n",
    "print(f'\\nT2: {(pca.T2>pca.T2_lim).sum()/pca.T2.shape[0]}')\n",
    "print(f'Q: {(pca.Q>pca.Q_lim).sum()/pca.Q.shape[0]}')\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,3))\n",
    "\n",
    "ax[0].semilogy(pca.T2,'.')\n",
    "ax[0].axhline(pca.T2_lim,ls='--',c='r')\n",
    "ax[0].axvline(3000,ls='--',c='k') # marca a pré-falha da 17\n",
    "ax[0].set_title('Carta de Controle $T^2$')\n",
    "ax[0].set_xlabel('Samples')\n",
    "ax[0].set_ylabel('$T^2$')\n",
    "\n",
    "ax[1].semilogy(pca.Q,'.')\n",
    "ax[1].axhline(pca.Q_lim,ls='--',c='r')\n",
    "ax[1].axvline(3000,ls='--',c='k')\n",
    "ax[1].set_title('Carta de Controle Q')\n",
    "ax[1].set_xlabel('Samples')\n",
    "ax[1].set_ylabel('$Q$')\n",
    "\n",
    "if fault is not None:\n",
    "    ax[0].axvline(fault, c='w')\n",
    "    ax[1].axvline(fault, c='w')\n",
    "\n",
    "pca.plot_contributions(columns=df_test.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f4dd7a",
   "metadata": {},
   "source": [
    "## 3. Métricas que permitem comparação com outros algoritmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0015701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.predict(x_test.drop(['rotulos_multi','rotulos_bin'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee79820",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'\\nT2: {(pca.T2>pca.T2_lim).sum()/pca.T2.shape[0]}')\n",
    "print(f'Q:  {(pca.Q>pca.Q_lim).sum()/pca.Q.shape[0]}')\n",
    "\n",
    "pca.plot_control_charts()\n",
    "plt.suptitle(f'Banco de teste');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc757a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_results = pd.DataFrame(columns=['T2', 'Q'])\n",
    "pca_results['T2'] = pca.T2\n",
    "pca_results['Q'] = pca.Q \n",
    "pca_results['rotulos_multi'] = y_test.values\n",
    "pca_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5940c785",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be282dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_results['T2_classific'] = np.where(pca_results['T2'] > pca.T2_lim, 1, 0)\n",
    "pca_results['Q_classific'] = np.where(pca_results['Q'] > pca.Q_lim, 1, 0)\n",
    "pca_results['rotulos_bin'] = np.where(pca_results['rotulos_multi'] >= 1, 1, 0)\n",
    "pca_results = pca_results.reset_index().drop(['index'], axis=1)\n",
    "pca_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb7941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desempenho por T2\n",
    "\n",
    "new_status = [0,1]\n",
    "\n",
    "df_cm = pd.DataFrame(confusion_matrix(pca_results['rotulos_bin'], pca_results['T2_classific']), \\\n",
    "                     index=[i for i in new_status], columns=[i for i in new_status])\n",
    "\n",
    "# Linha para normalizar os dados\n",
    "df_cm_norm = round((df_cm.astype('float')/df_cm.sum(axis=1).values.reshape(-1,1)), 3)\n",
    "\n",
    "# Gráfico da matriz de confusão\n",
    "plt.figure(figsize=(6,5), dpi=100)\n",
    "plt.title(\"Confusion Matrix - T2\", fontsize=10)\n",
    "ax = sns.heatmap(df_cm_norm, annot=True, cmap='PuBu')\n",
    "ax.set_xlabel(\"PREDICTED CLASSES\", fontsize=8)\n",
    "ax.set_ylabel(\"REAL CLASSES\", fontsize=8)\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.show()\n",
    "\n",
    "# Chama a função metrics()\n",
    "data_metrics = metrics(pca_results['rotulos_bin'], pca_results['T2_classific'], df_cm, new_status, \\\n",
    "                       multi_problem=False)\n",
    "\n",
    "print(\"\\nOverall Precision:       {:.2f}%\".format((data_metrics['Precision'].values.item()*100)))\n",
    "print(\"Overall Recall:          {:.2f}%\".format((data_metrics['Recall'].values.item()*100)))\n",
    "print(\"Overall F-score(a=1):    {:.2f}%\".format((data_metrics['F-score(a=1)'].values.item()*100)))\n",
    "print(\"Overall F-score(a=0.5):  {:.2f}%\".format((data_metrics['F-score(a=0.5)'].values.item()*100)))\n",
    "print(\"Overall F-score(a=2):    {:.2f}%\".format((data_metrics['F-score(a=2)'].values.item()*100)))\n",
    "print(\"Overall Specificity:     {:.2f}%\".format((data_metrics['Specificity'].values.item()*100)))\n",
    "print(\"Overall FPR(FAR):        {:.2f}%\".format((data_metrics['FPR(FAR)'].values.item()*100)))\n",
    "print(\"Overall Accuracy:        {:.2f}%\".format((data_metrics['Accuracy'].values.item()*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88812047",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7be0e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desempenho por Q\n",
    "\n",
    "new_status = [0,1]\n",
    "\n",
    "df_cm = pd.DataFrame(confusion_matrix(pca_results['rotulos_bin'], pca_results['Q_classific']), \\\n",
    "                     index=[i for i in new_status], columns=[i for i in new_status])\n",
    "\n",
    "# Linha para normalizar os dados\n",
    "df_cm_norm = round((df_cm.astype('float')/df_cm.sum(axis=1).values.reshape(-1,1)), 3)\n",
    "\n",
    "# Gráfico da matriz de confusão\n",
    "plt.figure(figsize=(6,5), dpi=100)\n",
    "plt.title(\"Confusion Matrix - Q\", fontsize=10)\n",
    "ax = sns.heatmap(df_cm_norm, annot=True, cmap='PuBu')\n",
    "ax.set_xlabel(\"PREDICTED CLASSES\", fontsize=8)\n",
    "ax.set_ylabel(\"REAL CLASSES\", fontsize=8)\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "plt.show()\n",
    "\n",
    "# Chama a função metrics()\n",
    "data_metrics = metrics(pca_results['rotulos_bin'], pca_results['Q_classific'], df_cm, new_status, \\\n",
    "                       multi_problem=False)\n",
    "\n",
    "print(\"\\nOverall Precision:       {:.2f}%\".format((data_metrics['Precision'].values.item()*100)))\n",
    "print(\"Overall Recall:          {:.2f}%\".format((data_metrics['Recall'].values.item()*100)))\n",
    "print(\"Overall F-score(a=1):    {:.2f}%\".format((data_metrics['F-score(a=1)'].values.item()*100)))\n",
    "print(\"Overall F-score(a=0.5):  {:.2f}%\".format((data_metrics['F-score(a=0.5)'].values.item()*100)))\n",
    "print(\"Overall F-score(a=2):    {:.2f}%\".format((data_metrics['F-score(a=2)'].values.item()*100)))\n",
    "print(\"Overall Specificity:     {:.2f}%\".format((data_metrics['Specificity'].values.item()*100)))\n",
    "print(\"Overall FPR(FAR):        {:.2f}%\".format((data_metrics['FPR(FAR)'].values.item()*100)))\n",
    "print(\"Overall Accuracy:        {:.2f}%\".format((data_metrics['Accuracy'].values.item()*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fb43ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
