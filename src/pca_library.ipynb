{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA():\n",
    "   \n",
    "    # ---------------------------------------------------------------------------\n",
    "    # Método construtor\n",
    "    # Função que será chamada toda vez que um objeto PCA for inicializado\n",
    "    # O modelo selecionará quantos PCs forem necessários para cumprir o % de variabilidade explicada especificado em a\n",
    "\n",
    "    def __init__ (self, a=0.9):\n",
    "\n",
    "        # se 0<=a<1,  'a' indica a fraçao de variancia explicada desejada\n",
    "        # se a>=1,    'a' indica o numero de componentes desejado\n",
    "        self.a = a\n",
    "   \n",
    "    # ---------------------------------------------------------------------------\n",
    "    # Função para treino do modelo\n",
    "    # X são os dados de treino\n",
    "    \n",
    "    def fit(self, X, conf_Q=0.99, conf_T2=0.99, plot=True):\n",
    "    \n",
    "        # guardando médias e desvios-padrão do treino (de cada coluna)\n",
    "        self.mu_train = X.mean(axis=0)\n",
    "        self.std_train = X.std(axis=0)        \n",
    "       \n",
    "        # normalizando dados de treino\n",
    "        X = np.array(((X - self.mu_train)/self.std_train))\n",
    "       \n",
    "        # calculando a matriz de covariâncias dos dados\n",
    "        Cx = np.cov(X, rowvar=False)\n",
    "        \n",
    "        # aplicando decomposição em autovalores e autovetores\n",
    "        self.L, self.P = np.linalg.eig(Cx)\n",
    "        \n",
    "        # frações da variância explicada\n",
    "        fv = self.L/np.sum(self.L)\n",
    "        \n",
    "        # frações da variância explicada acumuladas\n",
    "        fva = np.cumsum(self.L)/sum(self.L)\n",
    "       \n",
    "        # definindo número de componentes\n",
    "        if (self.a>0 and self.a<1):\n",
    "            self.a = np.where(fva>self.a)[0][0]+1 \n",
    "            \n",
    "        # calculando limites de detecção\n",
    "\n",
    "        # limite da estatística T^2\n",
    "        from scipy.stats import f\n",
    "        F = f.ppf(conf_T2, self.a, X.shape[0]-self.a)\n",
    "        self.T2_lim = ((self.a*(X.shape[0]**2-1))/(X.shape[0]*(X.shape[0]-self.a)))*F\n",
    "        \n",
    "        # limite da estatística Q\n",
    "        theta = [np.sum(self.L[self.a:]**(i)) for i in (1,2,3)]\n",
    "        ho = 1-((2*theta[0]*theta[2])/(3*(theta[1]**2)))\n",
    "        from scipy.stats import norm\n",
    "        nalpha = norm.ppf(conf_Q)\n",
    "        self.Q_lim = (theta[0]*(((nalpha*np.sqrt(2*theta[1]*ho**2))/theta[0])+1+\n",
    "                                ((theta[1]*ho*(ho-1))/theta[0]**2))**(1/ho))\n",
    "        \n",
    "        # plotando variâncias explicadas\n",
    "        if plot:\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.bar(np.arange(len(fv)),fv)\n",
    "            ax.plot(np.arange(len(fv)),fva)\n",
    "            ax.set_xlabel('Número de componentes')\n",
    "            ax.set_ylabel('Variância dos dados')\n",
    "            ax.set_title('PCA - Variância Explicada');\n",
    "\n",
    "    # ---------------------------------------------------------------------------\n",
    "    # Função para teste do modelo\n",
    "            \n",
    "    def predict(self, X):\n",
    "            \n",
    "        # normalizando dados de teste (usando os parâmetros do treino!)\n",
    "        X = np.array((X - self.mu_train)/self.std_train)\n",
    "\n",
    "        # calculando estatística T^2\n",
    "        T = X@self.P[:,:self.a]\n",
    "        self.T2 = np.array([T[i,:]@np.linalg.inv(np.diag(self.L[:self.a]))@T[i,:].T for i in range(X.shape[0])])\n",
    "\n",
    "        # calculando estatística Q\n",
    "        e = X - X@self.P[:,:self.a]@self.P[:,:self.a].T\n",
    "        self.Q  = np.array([e[i,:]@e[i,:].T for i in range(X.shape[0])])\n",
    "        \n",
    "        # calculando contribuições para Q\n",
    "        self.c = np.absolute(X*e) \n",
    "                \n",
    "    # ---------------------------------------------------------------------------\n",
    "    # Função para plotar cartas de controle\n",
    "    \n",
    "    def plot_control_charts(self, fault = None):\n",
    "     \n",
    "        fig, ax = plt.subplots(1,2, figsize=(15,3))\n",
    "\n",
    "        ax[0].semilogy(self.T2,'.')\n",
    "        ax[0].axhline(self.T2_lim,ls='--',c='r');\n",
    "        ax[0].set_title('Carta de Controle $T^2$')\n",
    "        \n",
    "        ax[1].semilogy(self.Q,'.')\n",
    "        ax[1].axhline(self.Q_lim,ls='--',c='r')\n",
    "        ax[1].set_title('Carta de Controle Q')\n",
    " \n",
    "        if fault is not None:\n",
    "            ax[0].axvline(fault, c='w')\n",
    "            ax[1].axvline(fault, c='w')\n",
    "\n",
    "    # ---------------------------------------------------------------------------\n",
    "    # Função para plotar mapas de contribuição\n",
    "            \n",
    "    def plot_contributions(self, fault=None, index=None, columns=None):\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(20, 6))\n",
    "        \n",
    "        c = pd.DataFrame(self.c, index=index, columns=columns)\n",
    "    \n",
    "        sns.heatmap(c, ax=ax, yticklabels=int(self.c.shape[0]/10), cmap = plt.cm.Blues)\n",
    "        \n",
    "        ax.set_title('Contribuições parciais para Q')\n",
    "        \n",
    "        if fault is not None:\n",
    "            ax.axhline(y=c.index[fault], ls='--', c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aceita um DataFrame e retorna outro contendo variáveis atrasadas\n",
    "\n",
    "def apply_lag(df, lag=1):\n",
    "    \n",
    "    # Aplica a função lagmat do statsmodels\n",
    "    # 'trim' é o método de corte a ser usado: ‘forward’ corta as observações inválidas na frente\n",
    "    # 'original' é como o array original é tratado: 'in' retorna o array original e o atrasado como dois arrays separados\n",
    "    # [lag:,:] desconsidera as linhas nas quais observações foram zeradas - ocorre com a aplicação dos lags\n",
    "    array_lagged = lagmat(df, maxlag=lag, trim=\"forward\", original='in')[lag:,:]  \n",
    "    new_columns = []\n",
    "    \n",
    "    # Armazena em um array os nomes das novas colunas atrasadas de acordo com quantos lags foram especificados\n",
    "    for l in range(lag):\n",
    "        new_columns.append(df.columns+'_lag'+str(l+1))\n",
    "    \n",
    "    # Unifica num array os nomes de todas as colunas, originais e atrasadas\n",
    "    columns_lagged = df.columns.append(new_columns)\n",
    "    \n",
    "    # Define os indexes do novo df que será criado\n",
    "    index_lagged = df.index[lag:]\n",
    "    \n",
    "    # Organiza o novo df, com o novo header, novos indexes e os dados originais e atrasados\n",
    "    df_lagged = pd.DataFrame(array_lagged, index=index_lagged, columns=columns_lagged)\n",
    "       \n",
    "    return df_lagged "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mspc_pca(data, IDV):\n",
    "    \n",
    "    df_test = data.query(\"STATUS == \" + str(IDV)).copy()\n",
    "    df_test.drop(['Time', 'Criticidade', 'HORIMETRO', 'STATUS', 'Run', 'MA(Run)'], 1, inplace=True)\n",
    "\n",
    "    try:\n",
    "        pca.predict(df_test)\n",
    "\n",
    "        pca.plot_control_charts()\n",
    "        plt.suptitle(f'ID({IDV})');\n",
    "\n",
    "        pca.plot_contributions(columns=df_test.columns)\n",
    "\n",
    "        print(f'Taxas de detecção de falhas - ID({IDV})')\n",
    "\n",
    "        print(f'\\nT2: {(pca.T2>pca.T2_lim).sum()/pca.T2.shape[0]}')\n",
    "        print(f'Q: {(pca.Q>pca.Q_lim).sum()/pca.Q.shape[0]}')\n",
    "    \n",
    "    except:\n",
    "        # pra quando o df fica vazio, por exemplo (o período não existe após algum drop)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
