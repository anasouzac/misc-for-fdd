{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import collections\n",
    "import math\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support , roc_auc_score, roc_curve, \\\n",
    "    auc, precision_score, recall_score, f1_score, accuracy_score\n",
    "from statsmodels.tsa.tsatools import lagmat\n",
    "\n",
    "%run ./config.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pós-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, iterator, train_type, model_name=\"\"):\n",
    "    \n",
    "    # Método 1\n",
    "    model_json = model.to_json()\n",
    "    with open(outputs_folder + train_type +  \"_model_\" + str(iterator) + \"-\" + model_name + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(outputs_folder + train_type +  \"_model_\" + str(iterator) + \".h5\")\n",
    "    \n",
    "    # Método 2\n",
    "    model.save(outputs_folder + train_type +  \"_model_\" + str(iterator) + \"-\" + model_name + \".h5\")\n",
    "    \n",
    "    # Salvando o history do treinamento em um CSV\n",
    "    pd.DataFrame.from_dict(model.history.history).to_csv(outputs_folder + train_type +  \"_model_\" + str(iterator) + \"-\" + model_name + \"-history.csv\", sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_roc_auc(x_data, y_data, model, model_name):\n",
    "    \n",
    "    # generate a no skill prediction (majority class)\n",
    "    ns_probs = [0 for _ in range(len(x_data))]\n",
    "\n",
    "    # predict probabilities\n",
    "    lr_probs = model.predict_proba(x_data)\n",
    "\n",
    "    # keep probabilities for the positive outcome only\n",
    "    lr_probs = lr_probs[:, 1]\n",
    "\n",
    "    # calculate scores\n",
    "    try:\n",
    "        ns_auc = roc_auc_score(y_data.argmax(axis=1), ns_probs)\n",
    "        lr_auc = roc_auc_score(y_data.argmax(axis=1), lr_probs)\n",
    "        \n",
    "        # calculate roc curves\n",
    "        ns_fpr, ns_tpr, _ = roc_curve(y_data.argmax(axis=1), ns_probs)\n",
    "        lr_fpr, lr_tpr, _ = roc_curve(y_data.argmax(axis=1), lr_probs)\n",
    "    except:\n",
    "        ns_auc = roc_auc_score(y_data, ns_probs)\n",
    "        lr_auc = roc_auc_score(y_data, lr_probs)\n",
    "        \n",
    "        # calculate roc curves\n",
    "        ns_fpr, ns_tpr, _ = roc_curve(y_data, ns_probs)\n",
    "        lr_fpr, lr_tpr, _ = roc_curve(y_data, lr_probs)\n",
    "\n",
    "    # summarize scores\n",
    "    print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "    print(model_name + ': ROC AUC=%.3f' % (lr_auc))\n",
    "\n",
    "    # plot the roc curve for the model\n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "    plt.plot(lr_fpr, lr_tpr, marker='.', label=model_name)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_real, y_pred, model, conf_matrix, STATUS, multi_problem):\n",
    "    \n",
    "    # Classificação multiclass\n",
    "    if (multi_problem):\n",
    "    \n",
    "        cm_values = conf_matrix.values\n",
    "    \n",
    "        # Cálculo dos FP, FN e TP para cada classe\n",
    "        tp = np.zeros((len(cm_values),1))\n",
    "        tn = np.zeros((len(cm_values),1))\n",
    "        fp = np.zeros((len(cm_values),1))\n",
    "        fn = np.zeros((len(cm_values),1))\n",
    "        acc = np.zeros((len(cm_values),1))\n",
    "\n",
    "        for i in range(0, len(cm_values)):\n",
    "\n",
    "            tp[i] = cm_values[i,i]\n",
    "            fp[i] = cm_values[:,i].sum() - cm_values[i,i]\n",
    "            fn[i] = cm_values[i,:].sum() - cm_values[i,i]\n",
    "            tn[i] = len(y_real) - tp[i] - fp[i] - fn[i]\n",
    "            acc[i] = (len(y_real) - (cm_values[i,:].sum() + cm_values[:,i].sum() - 2*cm_values[i,i]))/len(y_real)\n",
    "\n",
    "        # Cálculo das métricas Precision, Recall e F-Score para cada classe\n",
    "        try:\n",
    "            metricas = precision_recall_fscore_support(y_real.argmax(axis=1), y_pred.argmax(axis=1), zero_division=0)\n",
    "        except:\n",
    "            metricas = precision_recall_fscore_support(y_real, y_pred, zero_division=0)\n",
    "\n",
    "        # Arranjo do dataframe e inclusão de outras métricas\n",
    "        metricas_df = pd.DataFrame(list(metricas))\n",
    "        metricas_df = metricas_df.transpose()\n",
    "\n",
    "        metricas_df.columns = ['Precision', 'Recall', 'F-score(a=1)', 'Total']\n",
    "        metricas_df['Accuracy'] = acc\n",
    "        metricas_df['Class'] = STATUS\n",
    "        metricas_df['Total'] = metricas_df['Total'].astype(int)\n",
    "\n",
    "        metricas_df['TP'] = tp.astype(int)\n",
    "        metricas_df['TN'] = tn.astype(int)\n",
    "        metricas_df['FP'] = fp.astype(int)\n",
    "        metricas_df['FN'] = fn.astype(int)\n",
    "\n",
    "        metricas_df['Specificity'] = (metricas_df['TN']/(metricas_df['TN'] + metricas_df['FP']))\n",
    "        metricas_df['FPR(FAR)'] = (metricas_df['FP']/(metricas_df['FP'] + metricas_df['TN']))\n",
    "        metricas_df['F-score(a=0.5)'] =\\\n",
    "            (1.5*metricas_df['Precision']*metricas_df['Recall'])/((0.5*metricas_df['Precision']) + metricas_df['Recall'])\n",
    "        metricas_df['F-score(a=2)'] =\\\n",
    "            (3*metricas_df['Precision']*metricas_df['Recall'])/((2*metricas_df['Precision']) + metricas_df['Recall'])\n",
    "        metricas_df['F-score(a=0.5)'].fillna(0, inplace=True)\n",
    "        metricas_df['F-score(a=2)'].fillna(0, inplace=True)\n",
    "\n",
    "        metricas_df = metricas_df.set_index('Class')\n",
    "        metricas_df = metricas_df[['Precision', 'Recall', 'F-score(a=1)', 'F-score(a=0.5)', 'F-score(a=2)', \\\n",
    "                                   'Specificity', 'Accuracy', 'FPR(FAR)', 'TP', 'TN', 'FP', 'FN', 'Total']]\n",
    "    \n",
    "    # Classificação binária\n",
    "    else:\n",
    "        \n",
    "        try:\n",
    "            tn, fp, fn, tp = confusion_matrix(y_real.argmax(axis=1), y_pred.argmax(axis=1)).ravel()\n",
    "        except:\n",
    "            tn, fp, fn, tp = confusion_matrix(y_real, y_pred).ravel()\n",
    "        \n",
    "        recall = tp/(tp+fn)\n",
    "        precision = tp/(tp+fp)\n",
    "        f1_score = 2*recall*precision/(recall+precision)\n",
    "        f2_score = 3*recall*precision/((2*precision)+recall)\n",
    "        f05_score = 1.5*recall*precision/((0.5*precision)+recall)\n",
    "        accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "        specificity = tn/(fp+tn)\n",
    "        fpr = fp/(fp+tn)\n",
    "        \n",
    "        metricas_df = pd.DataFrame([precision, recall, f1_score, f05_score, f2_score, specificity, accuracy, fpr, tp, \\\n",
    "                                    tn, fp, fn]).T\n",
    "        metricas_df.columns = ['Precision', 'Recall', 'F-score(a=1)', 'F-score(a=0.5)', 'F-score(a=2)', \\\n",
    "                               'Specificity', 'Accuracy', 'FPR(FAR)', 'TP', 'TN', 'FP', 'FN']\n",
    "\n",
    "    return metricas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_metrics(x_data, y_data, model, STATUS, set_name, multi_problem):\n",
    "    \n",
    "    # Predição usando o modelo treinado\n",
    "    model_pred = model.predict(x_data)\n",
    "    try:\n",
    "        new_status = np.unique(model_pred.argmax(axis=1))\n",
    "    except:\n",
    "        new_status = np.unique(model_pred)\n",
    "\n",
    "    try:\n",
    "        try:\n",
    "            df_cm = pd.DataFrame(confusion_matrix(y_data.argmax(axis=1), model_pred.argmax(axis=1)), \\\n",
    "                                 index=[i for i in new_status], columns=[i for i in new_status])\n",
    "        except:\n",
    "            df_cm = pd.DataFrame(confusion_matrix(y_data, model_pred, index=[i for i in new_status],\n",
    "                          columns=[i for i in new_status]))\n",
    "    except:\n",
    "        df_cm = pd.DataFrame(confusion_matrix(y_data, model_pred))\n",
    "\n",
    "    # Linha para normalizar os dados\n",
    "    df_cm_norm = round((df_cm.astype('float')/df_cm.sum(axis=1).values.reshape(-1,1)), 3)\n",
    "    \n",
    "    # Gráfico da matriz de confusão\n",
    "    plt.figure(figsize=(6,5), dpi=100)\n",
    "    plt.title(\"Confusion Matrix - \" + set_name + \" - CNN\", fontsize=10)\n",
    "    ax = sn.heatmap(df_cm_norm, annot=True, cmap='PuBu')\n",
    "    ax.set_xlabel(\"PREDICTED CLASSES\", fontsize=8)\n",
    "    ax.set_ylabel(\"REAL CLASSES\", fontsize=8)\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "    plt.show()\n",
    "    \n",
    "    # Chama a função metrics()\n",
    "    data_metrics = metrics(y_data, model_pred, model, df_cm, STATUS, multi_problem)\n",
    "    \n",
    "    if (multi_problem):\n",
    "        pr_micro = precision_score(y_data.argmax(axis=1), model_pred.argmax(axis=1), labels=STATUS, average='micro')\n",
    "        pr_macro = precision_score(y_data.argmax(axis=1), model_pred.argmax(axis=1), labels=STATUS, average='macro')\n",
    "        pr_weigh = precision_score(y_data.argmax(axis=1), model_pred.argmax(axis=1), labels=STATUS, average='weighted')\n",
    "\n",
    "        rc_micro = recall_score(y_data.argmax(axis=1), model_pred.argmax(axis=1), labels=STATUS, average='micro')\n",
    "        rc_macro = recall_score(y_data.argmax(axis=1), model_pred.argmax(axis=1), labels=STATUS, average='macro')\n",
    "        rc_weigh = recall_score(y_data.argmax(axis=1), model_pred.argmax(axis=1), labels=STATUS, average='weighted')\n",
    "\n",
    "        f1_micro = f1_score(y_data.argmax(axis=1), model_pred.argmax(axis=1), labels=STATUS, average='micro')\n",
    "        f1_macro = f1_score(y_data.argmax(axis=1), model_pred.argmax(axis=1), labels=STATUS, average='macro')\n",
    "        f1_weigh = f1_score(y_data.argmax(axis=1), model_pred.argmax(axis=1), labels=STATUS, average='weighted')\n",
    "\n",
    "        print(\"PRECISION\")\n",
    "        print(\"micro:    {:.2f}%\".format((pr_micro*100)))\n",
    "        print(\"macro:    {:.2f}%\".format((pr_macro*100)))\n",
    "        print(\"weighted: {:.2f}%\".format((pr_weigh*100)))\n",
    "\n",
    "        print(\"\\nRECALL\")\n",
    "        print(\"micro:    {:.2f}%\".format((rc_micro*100)))\n",
    "        print(\"macro:    {:.2f}%\".format((rc_macro*100)))\n",
    "        print(\"weighted: {:.2f}%\".format((rc_weigh*100)))\n",
    "\n",
    "        print(\"\\nF-SCORE (a=1)\")\n",
    "        print(\"micro:    {:.2f}%\".format((f1_micro*100)))\n",
    "        print(\"macro:    {:.2f}%\".format((f1_macro*100)))\n",
    "        print(\"weighted: {:.2f}%\".format((f1_weigh*100)))\n",
    "        print()\n",
    "        \n",
    "        try:\n",
    "            print(\"Overall AUC:       {:.2f}%\".format((roc_auc_score(y_data, model_pred)*100)))\n",
    "        except:\n",
    "            pass\n",
    "        print(\"Overall Accuracy:    {:.2f}%\".format(accuracy_score(y_data.argmax(axis=1), model_pred.argmax(axis=1))*100))\n",
    "    \n",
    "    else: \n",
    "        print(\"\\nOverall Precision:       {:.2f}%\".format((data_metrics['Precision'].values.item()*100)))\n",
    "        print(\"Overall Recall:          {:.2f}%\".format((data_metrics['Recall'].values.item()*100)))\n",
    "        print(\"Overall F-score(a=1):    {:.2f}%\".format((data_metrics['F-score(a=1)'].values.item()*100)))\n",
    "        print(\"Overall F-score(a=0.5):  {:.2f}%\".format((data_metrics['F-score(a=0.5)'].values.item()*100)))\n",
    "        print(\"Overall F-score(a=2):    {:.2f}%\".format((data_metrics['F-score(a=2)'].values.item()*100)))\n",
    "        print(\"Overall Specificity:     {:.2f}%\".format((data_metrics['Specificity'].values.item()*100)))\n",
    "        print(\"Overall FPR(FAR):        {:.2f}%\".format((data_metrics['FPR(FAR)'].values.item()*100)))\n",
    "        print(\"Overall Accuracy:        {:.2f}%\".format((data_metrics['Accuracy'].values.item()*100)))\n",
    "    \n",
    "    return data_metrics  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrige_status(status, X_train, X_test, X_valid):\n",
    "    \n",
    "    # Cria uma nova coluna auxiliar\n",
    "    status['soma'] = status['status_duration'].cumsum()\n",
    "    status['soma'].iloc[0] = 0\n",
    "    \n",
    "    # Indexes de \"quebra\" de acordo com a divisão feita pelo train_test_split\n",
    "    x_train_end = X_train.index.max()\n",
    "    x_val_init = x_train_end + 1\n",
    "    x_val_end = X_valid.index.max()\n",
    "    x_test_init = x_val_end + 1\n",
    "    \n",
    "    # Percorre o banco de parâmetros\n",
    "    # Precisa encontrar em qual intervalo o index de \"quebra\" do banco original se encontra\n",
    "    for i in range(len(status)):\n",
    "    \n",
    "        try:\n",
    "            low_lim = status['soma'].iloc[i]\n",
    "            upper_lim = status['soma'].iloc[i+1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if (low_lim <= x_train_end <= upper_lim):\n",
    "            train_temp = status.iloc[:i+2,:]\n",
    "            diff_train = x_train_end - train_temp['soma'].iloc[-2] + 1\n",
    "\n",
    "            status_train = train_temp.copy()\n",
    "            status_train['status_duration'].iloc[-1] = diff_train\n",
    "            status_train.drop(['soma'], 1, inplace=True)\n",
    "            \n",
    "            train_len = status_train.status_duration.sum()\n",
    "\n",
    "        if (low_lim <= x_val_end <= upper_lim):\n",
    "            valid_temp = status.iloc[status_train.index.max():i+2,:]\n",
    "            diff_valid = x_val_end - valid_temp['soma'].iloc[-2] + 1\n",
    "\n",
    "            status_valid = valid_temp.copy()\n",
    "            status_valid['status_duration'].iloc[0] = status_valid['status_duration'].iloc[0] - diff_train\n",
    "            status_valid['status_duration'].iloc[-1] = diff_valid\n",
    "            status_valid.drop(['soma'], 1, inplace=True)\n",
    "            \n",
    "            valid_len = status_valid.status_duration.sum()\n",
    "\n",
    "        if (low_lim <= x_test_init <= upper_lim):\n",
    "            test_temp = status.iloc[status_valid.index.max():,:]\n",
    "\n",
    "            status_test = test_temp.copy()\n",
    "            status_test['status_duration'].iloc[0] = status_test['status_duration'].iloc[0] - diff_valid\n",
    "            status_test.drop(['soma'], 1, inplace=True)\n",
    "            \n",
    "            test_len = status_test.status_duration.sum()\n",
    "    \n",
    "    # Conferência\n",
    "    if (status.soma.iloc[-1] == (train_len+valid_len+test_len)):\n",
    "        print(\"Divisão dos bancos de dados concluída!\")\n",
    "    else:\n",
    "        raise ValueError('A divisão dos bancos de dados não foi feita corretamente')\n",
    "    \n",
    "    return status_train, status_valid, status_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para quando se tem apenas treino e teste\n",
    "\n",
    "def corrige_status_2sets(status, X_train, X_test):\n",
    "    \n",
    "    # Cria uma nova coluna auxiliar\n",
    "    status['soma'] = status['status_duration'].cumsum()\n",
    "    status['soma'].iloc[0] = 0\n",
    "    \n",
    "    # Indexes de \"quebra\" de acordo com a divisão feita pelo train_test_split\n",
    "    x_train_end = X_train.index.max()\n",
    "    x_test_init = x_train_end + 1\n",
    "    \n",
    "    # Percorre o banco de parâmetros\n",
    "    # Precisa encontrar em qual intervalo o index de \"quebra\" do banco original se encontra\n",
    "    for i in range(len(status)):\n",
    "    \n",
    "        try:\n",
    "            low_lim = status['soma'].iloc[i]\n",
    "            upper_lim = status['soma'].iloc[i+1]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if (low_lim <= x_train_end <= upper_lim):\n",
    "            train_temp = status.iloc[:i+2,:]\n",
    "            diff_train = x_train_end - train_temp['soma'].iloc[-2] + 1\n",
    "\n",
    "            status_train = train_temp.copy()\n",
    "            status_train['status_duration'].iloc[-1] = diff_train\n",
    "            status_train.drop(['soma'], 1, inplace=True)\n",
    "            \n",
    "            train_len = status_train.status_duration.sum()\n",
    "\n",
    "        if (low_lim <= x_test_init <= upper_lim):\n",
    "            test_temp = status.iloc[status_train.index.max():,:]\n",
    "\n",
    "            status_test = test_temp.copy()\n",
    "            status_test['status_duration'].iloc[0] = status_test['status_duration'].iloc[0] - diff_train\n",
    "            status_test.drop(['soma'], 1, inplace=True)\n",
    "            \n",
    "            test_len = status_test.status_duration.sum()\n",
    "    \n",
    "    # Conferência\n",
    "    if (status.soma.iloc[-1] == (train_len+test_len)):\n",
    "        print(\"Divisão dos bancos de dados concluída!\")\n",
    "    else:\n",
    "        raise ValueError('A divisão dos bancos de dados não foi feita corretamente')\n",
    "    \n",
    "    return status_train, status_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_scaling(X_train, X_test, X_valid, scaling_mode):\n",
    "    \n",
    "    # Inicializa o dataframe onde as métricas do banco de treino serão armazenadas\n",
    "    scaling_info = pd.DataFrame(range(len(X_train.columns)), columns=['mean_train'])\n",
    "    scaling_info['std_train'] = np.zeros(())\n",
    "    scaling_info['max_train'] = np.zeros(())\n",
    "    scaling_info['min_train'] = np.zeros(())\n",
    "    \n",
    "    i=0\n",
    "    # Calcula as métricas de cada coluna do banco de treino e armazena no df sacaling_info\n",
    "    for col in X_train.columns:\n",
    "    \n",
    "        col_mean = X_train[col].mean()\n",
    "        scaling_info['mean_train'].iloc[i] = col_mean\n",
    "\n",
    "        col_std = X_train[col].std()\n",
    "        scaling_info['std_train'].iloc[i] = col_std\n",
    "\n",
    "        col_max = X_train[col].max()\n",
    "        scaling_info['max_train'].iloc[i] = col_max\n",
    "\n",
    "        col_min = X_train[col].min()\n",
    "        scaling_info['min_train'].iloc[i] = col_min\n",
    "\n",
    "        i+=1\n",
    "    \n",
    "    DATASET_DICT = {'train': X_train, 'valid': X_valid, 'test': X_test}\n",
    "    SCALED_DATASET_DICT = {}\n",
    "    \n",
    "    # Percorre cada um bancos previamente divididos e aplica o scaling selecionado\n",
    "    for key in DATASET_DICT.keys():\n",
    "        data = DATASET_DICT[key]\n",
    "        \n",
    "        i=0\n",
    "        for col in data.columns:\n",
    "            \n",
    "            if (scaling_mode == 'standardizing'):\n",
    "                data[col] = (data[col]-scaling_info['mean_train'].iloc[i])/scaling_info['std_train'].iloc[i]\n",
    "            \n",
    "            if (scaling_mode == 'normalizing_0'):\n",
    "                data[col] = (data[col]-scaling_info['min_train'].iloc[i])/(scaling_info['max_train'].iloc[i]- \\\n",
    "                                                                           scaling_info['min_train'].iloc[i])\n",
    "        \n",
    "            if (scaling_mode == 'normalizing_1'):\n",
    "                data[col] = (data[col]-scaling_info['min_train'].iloc[i])/(scaling_info['max_train'].iloc[i]- \\\n",
    "                                                                           scaling_info['min_train'].iloc[i])\n",
    "                data[col] = (data[col]*2) - 1\n",
    "            \n",
    "            i+=1\n",
    "        \n",
    "        SCALED_DATASET_DICT[key] = data.copy()\n",
    "    \n",
    "    print(\"Scaling dos bancos de dados concluído!\")\n",
    "    print()\n",
    "    \n",
    "    return SCALED_DATASET_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para quando se tem apenas treino e teste\n",
    "\n",
    "def data_scaling_2sets(X_train, X_test, scaling_mode, X_valid=pd.DataFrame()):\n",
    "    \n",
    "    # Inicializa o dataframe onde as métricas do banco de treino serão armazenadas\n",
    "    scaling_info = pd.DataFrame(range(len(X_train.columns)), columns=['mean_train'])\n",
    "    scaling_info['std_train'] = np.zeros(())\n",
    "    scaling_info['max_train'] = np.zeros(())\n",
    "    scaling_info['min_train'] = np.zeros(())\n",
    "    \n",
    "    i=0\n",
    "    # Calcula as métricas de cada coluna do banco de treino e armazena no df sacaling_info\n",
    "    for col in X_train.columns:\n",
    "    \n",
    "        col_mean = X_train[col].mean()\n",
    "        scaling_info['mean_train'].iloc[i] = col_mean\n",
    "\n",
    "        col_std = X_train[col].std()\n",
    "        scaling_info['std_train'].iloc[i] = col_std\n",
    "\n",
    "        col_max = X_train[col].max()\n",
    "        scaling_info['max_train'].iloc[i] = col_max\n",
    "\n",
    "        col_min = X_train[col].min()\n",
    "        scaling_info['min_train'].iloc[i] = col_min\n",
    "\n",
    "        i+=1\n",
    "    \n",
    "    DATASET_DICT = {'train': X_train, 'valid': X_valid, 'test': X_test}\n",
    "    SCALED_DATASET_DICT = {}\n",
    "    \n",
    "    # Percorre cada um bancos previamente divididos e aplica o scaling selecionado\n",
    "    for key in DATASET_DICT.keys():\n",
    "        data = DATASET_DICT[key]\n",
    "        \n",
    "        i=0\n",
    "        for col in data.columns:\n",
    "            \n",
    "            if (scaling_mode == 'standardizing'):\n",
    "                data[col] = (data[col]-scaling_info['mean_train'].iloc[i])/scaling_info['std_train'].iloc[i]\n",
    "            \n",
    "            if (scaling_mode == 'normalizing_0'):\n",
    "                data[col] = (data[col]-scaling_info['min_train'].iloc[i])/(scaling_info['max_train'].iloc[i]- \\\n",
    "                                                                           scaling_info['min_train'].iloc[i])\n",
    "        \n",
    "            if (scaling_mode == 'normalizing_1'):\n",
    "                data[col] = (data[col]-scaling_info['min_train'].iloc[i])/(scaling_info['max_train'].iloc[i]- \\\n",
    "                                                                           scaling_info['min_train'].iloc[i])\n",
    "                data[col] = (data[col]*2) - 1\n",
    "            \n",
    "            i+=1\n",
    "        \n",
    "        SCALED_DATASET_DICT[key] = data.copy()\n",
    "    \n",
    "    print(\"Scaling dos bancos de dados concluído!\")\n",
    "    print()\n",
    "    \n",
    "    return SCALED_DATASET_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_stride_ana(array, max_time, sub_window_size, stride_size):\n",
    "    \n",
    "    sub_windows = ( \n",
    "        np.expand_dims(np.arange(sub_window_size), 0) +\n",
    "        np.expand_dims(np.arange(max_time + 1), 0).T\n",
    "    )\n",
    "    \n",
    "    # Descobre o index da última coluna do array\n",
    "    last_col_index = (array.shape[1])-1\n",
    "    \n",
    "    # Linha da matriz de índices que vai até o tamanho total do trecho que será convertido em matrizes\n",
    "    cut_point = np.where(sub_windows[:,last_col_index] == len(array)-1)[0].item()\n",
    "    \n",
    "    # Faz o corte\n",
    "    sub_windows_new = sub_windows[:cut_point]\n",
    "    \n",
    "    # Fancy indexing to select every V rows.\n",
    "    return array[sub_windows_new[::stride_size]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nova estratégia utilizando recursos de indexação do numpy\n",
    "\n",
    "def matrix_generator(scaled_data, status_data, nlinhas, ncolunas, sliding_window):\n",
    "    \n",
    "    x_windows = np.empty(shape=(1, nlinhas, ncolunas, 1))\n",
    "    y_windows = np.array([])\n",
    "    \n",
    "    # Converte o df com dados de entrada em um array\n",
    "    x_array = scaled_data.values\n",
    "\n",
    "    c = status_data.iloc[0,1]  # Obtem o tamanho do primeiro dataset\n",
    "    ct1 = 0\n",
    "    ct2 = 0\n",
    "    ct3 = 0 \n",
    "\n",
    "    for j in range(len(status_data)):\n",
    "\n",
    "        # Necessário para fazer a primeira concatenação - não é vazio\n",
    "        x_data = np.empty(shape=(1, nlinhas, ncolunas, 1)) \n",
    "        data = x_array[ct1:c+ct2,:] \n",
    "\n",
    "        # Necessário para lidar com o fato do primeiro índice em python ser o zero\n",
    "        if ct3 < len(status_data)-1:\n",
    "            tamanho = status_data.iloc[ct3+1,1]\n",
    "\n",
    "        # Atualização dos contadores auxiliares para a próxima iteração\n",
    "        ct1 = c + ct2\n",
    "        ct2 = ct2 + tamanho                                                          \n",
    "        ct3 = ct3 + 1\n",
    "        \n",
    "        print(\"---------------------------------------------------\")\n",
    "        print(\"Status: \", status_data.iloc[j,0])\n",
    "        if len(data) < nlinhas:\n",
    "            print(\"Status com tamanho menor ao da janela. Dados ignorados!\")\n",
    "        else:\n",
    "            windows_num = int((len(data)-nlinhas)/sliding_window)+1\n",
    "            print(\"Número de janelas: \", windows_num)\n",
    "\n",
    "            # Chama a função que cria as matrizes para o status em questão e faz o reshape necessário\n",
    "            res = vectorized_stride_ana(data, len(data)-1, nlinhas, sliding_window)\n",
    "            x_data_slice_reshape = res.reshape((len(res), nlinhas, ncolunas, 1), order='C')\n",
    "\n",
    "            # Cria um vetor com os labels de cada matriz\n",
    "            matrix_len = len(x_data_slice_reshape)\n",
    "            y_data = np.full((matrix_len), status_data.iloc[j,0])    \n",
    "            \n",
    "            # Empilha as matrizes criadas numa única variável\n",
    "            x_windows = np.concatenate([x_windows, x_data_slice_reshape])\n",
    "            y_windows = np.append(y_windows, y_data)\n",
    "\n",
    "    # Remove o primeiro array referente ao np.empty inicial\n",
    "    x_windows = x_windows[1:, :] \n",
    "    \n",
    "    # Quando nem todos os STATUS estão presentes no banco, 'get_dummies' é uma alternativa\n",
    "    y_windows_df = pd.DataFrame(y_windows).astype('category')\n",
    "    y_windows_df_ohe = pd.get_dummies(y_windows_df)\n",
    "    y_windows_ohe = y_windows_df_ohe.values\n",
    "    \n",
    "    return x_windows, y_windows, y_windows_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepro(\n",
    "    raw_input, targets, status, nlinhas, ncolunas, sliding_window, test_size, valid_size, scaling_mode):\n",
    "    \n",
    "    # Divisão do banco total entre treino, validação e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(raw_input, targets, test_size=test_size, shuffle=False)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=valid_size, shuffle=False)\n",
    "    \n",
    "    # Gerando 03 novos dfs com as informações de status e durações corrigidas\n",
    "    status_train, status_valid, status_test = corrige_status(status, X_train, X_test, X_valid)\n",
    "    \n",
    "    # Scaling dos bancos de dados de acordo com o dataset de treinamento\n",
    "    SCALED_DATASET_DICT = data_scaling(X_train, X_test, X_valid, scaling_mode)\n",
    "    \n",
    "    # Gerando as matrizes para cada banco de dados\n",
    "    x_windows_train, y_windows_train, y_windows_ohe_train =\\\n",
    "        matrix_generator(SCALED_DATASET_DICT['train'], status_train, nlinhas, ncolunas, sliding_window)\n",
    "    \n",
    "    x_windows_valid, y_windows_valid, y_windows_ohe_valid =\\\n",
    "        matrix_generator(SCALED_DATASET_DICT['valid'], status_valid, nlinhas, ncolunas, sliding_window)\n",
    "    \n",
    "    x_windows_test, y_windows_test, y_windows_ohe_test =\\\n",
    "        matrix_generator(SCALED_DATASET_DICT['test'], status_test, nlinhas, ncolunas, sliding_window)\n",
    "    \n",
    "    print(\"\\nReshape dos dados em arrays 4D concluído!\")\n",
    "    \n",
    "    return x_windows_train, y_windows_train, y_windows_ohe_train, x_windows_valid, y_windows_valid, y_windows_ohe_valid, \\\n",
    "            x_windows_test, y_windows_test, y_windows_ohe_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lag(df, lag=1):\n",
    "    \n",
    "    # Aplica a função lagmat do statsmodels\n",
    "    # 'trim' é o método de corte a ser usado: ‘forward’ corta as observações inválidas na frente\n",
    "    # 'original' é como o array original é tratado: 'in' retorna o array original e o atrasado como dois arrays separados\n",
    "    # [lag:,:] desconsidera as linhas nas quais observações foram zeradas - ocorre com a aplicação dos lags\n",
    "    array_lagged = lagmat(df, maxlag=lag, trim=\"forward\", original='in')[lag:,:]  \n",
    "    new_columns = []\n",
    "    \n",
    "    # Armazena em um array os nomes das novas colunas atrasadas de acordo com quantos lags foram especificados\n",
    "    for l in range(lag):\n",
    "        new_columns.append(df.columns+'_lag'+str(l+1))\n",
    "    \n",
    "    # Unifica num array os nomes de todas as colunas, originais e atrasadas\n",
    "    columns_lagged = df.columns.append(new_columns)\n",
    "    \n",
    "    # Define os indexes do novo df que será criado\n",
    "    index_lagged = df.index[lag:]\n",
    "    \n",
    "    # Organiza o novo df, com o novo header, novos indexes e os dados originais e atrasados\n",
    "    df_lagged = pd.DataFrame(array_lagged, index=index_lagged, columns=columns_lagged)\n",
    "       \n",
    "    return df_lagged "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pouco performático\n",
    "# Percorrendo o dataframe por um loop e usando loc e iloc\n",
    "\n",
    "# def matrix_generator(scaled_data, status_data, nlinhas, ncolunas, sliding_window):\n",
    "    \n",
    "#     x_windows = np.empty(shape=(1, nlinhas, ncolunas, 1))\n",
    "#     y_windows = np.array([])\n",
    "\n",
    "#     c = status_data.iloc[0,1]  # Obtem o tamanho do primeiro dataset\n",
    "#     ct1 = 0\n",
    "#     ct2 = 0\n",
    "#     ct3 = 0 \n",
    "\n",
    "#     for j in range(len(status_data)):\n",
    "\n",
    "#         x_data = np.empty(shape=(1, nlinhas, ncolunas, 1)) # Necessário para fazer a primeira concatenação - não é vazio\n",
    "#         data = scaled_data.iloc[ct1:c+ct2,:] \n",
    "\n",
    "#         # Necessário para lidar com o fato do primeiro índice em python ser o zero\n",
    "#         if ct3 < len(status_data)-1:\n",
    "#             tamanho = status_data.iloc[ct3+1,1]\n",
    "\n",
    "#         # Atualização dos contadores auxiliares para a próxima iteração\n",
    "#         ct1 = c + ct2\n",
    "#         ct2 = ct2 + tamanho                                                          \n",
    "#         ct3 = ct3 + 1\n",
    "\n",
    "#         # Informa se é possível construir uma janela de dados com o trecho do banco selecionado\n",
    "#         if len(data) < nlinhas:\n",
    "#             print(\"Status com tamanho menor ao da janela. Dados ignorados!\")\n",
    "#         else:\n",
    "#             windows_num = int((len(data)-nlinhas)/sliding_window)+1\n",
    "#             print(\"Número de janelas: \", windows_num)\n",
    "\n",
    "#             y_data = np.empty((windows_num, 1))\n",
    "\n",
    "#             for i in range(0, windows_num):\n",
    "#                 x_data_slice = data.iloc[(i*sliding_window):((i*sliding_window)+nlinhas), :]\n",
    "#                 x_data_slice_reshape = x_data_slice.values.reshape((1, nlinhas, ncolunas, 1), order='C')\n",
    "#                 x_data = np.concatenate([x_data, x_data_slice_reshape]) \n",
    "#                 y_data[i] = status_data.iloc[j,0]\n",
    "\n",
    "#             x_data = x_data[1:, :] # Remove o primeiro array referente ao np.empty inicial\n",
    "#             x_windows = np.concatenate([x_windows, x_data])\n",
    "#             y_windows = np.append(y_windows, y_data)        \n",
    "\n",
    "#     x_windows = x_windows[1:, :] # Remove o primeiro array referente ao np.empty inicial\n",
    "    \n",
    "#     # Quando nem todos os STATUS estão presentes no banco, 'get_dummies' é uma alternativa\n",
    "#     y_windows_df = pd.DataFrame(y_windows).astype('category')\n",
    "#     y_windows_df_ohe = pd.get_dummies(y_windows_df)\n",
    "#     y_windows_ohe = y_windows_df_ohe.values\n",
    "    \n",
    "#     return x_windows, y_windows, y_windows_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quando data leaking estava ocorrendo\n",
    "\n",
    "# def data_prepro_antigo(raw_data, sim_status, nlinhas, ncolunas, sliding_window, standardization=False):\n",
    "    \n",
    "#     if (standardization == False):\n",
    "#         min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "#         scaled = min_max_scaler.fit_transform(raw_data)\n",
    "#         data_total_norm = pd.DataFrame(scaled, index=raw_data.index, columns=raw_data.columns)\n",
    "#     else:\n",
    "#         scaled = preprocessing.scale(raw_data)\n",
    "#         data_total_norm = pd.DataFrame(scaled, index=raw_data.index, columns=raw_data.columns)\n",
    "    \n",
    "#     x_windows = np.empty(shape=(1, nlinhas, ncolunas, 1))\n",
    "#     y_windows = np.array([])\n",
    "\n",
    "#     c = sim_status.iloc[0,1]  # Obtem o tamanho do primeiro dataset\n",
    "#     ct1 = 0\n",
    "#     ct2 = 0\n",
    "#     ct3 = 0 \n",
    "\n",
    "#     for j in range(len(sim_status)):\n",
    "\n",
    "#         x_data = np.empty(shape=(1, nlinhas, ncolunas, 1)) # Necessário para fazer a primeira concatenação - não é vazio\n",
    "#         data = data_total_norm.iloc[ct1:c+ct2,:] # não teria que ter um iloc?\n",
    "\n",
    "#         # Necessário para lidar com o fato do primeiro índice em python ser o zero\n",
    "#         if ct3 < len(sim_status)-1:\n",
    "#             tamanho = sim_status.iloc[ct3+1,1]\n",
    "\n",
    "#         # Atualização dos contadores auxiliares para a próxima iteração\n",
    "#         ct1 = c + ct2\n",
    "#         ct2 = ct2 + tamanho                                                          \n",
    "#         ct3 = ct3 + 1\n",
    "\n",
    "#         if len(data) < nlinhas:\n",
    "#             print(\"Status com tamanho menor ao da janela. Dados ignorados!\")\n",
    "#         else:\n",
    "#             windows_num = int((len(data)-nlinhas)/sliding_window)+1\n",
    "#             print(\"Número de janelas: \", windows_num)\n",
    "\n",
    "#             y_data = np.empty((windows_num, 1))\n",
    "\n",
    "#             for i in range(0, windows_num):\n",
    "#                 x_data_slice = data.iloc[(i*sliding_window):((i*sliding_window)+nlinhas), :]\n",
    "#                 x_data_slice_reshape = x_data_slice.values.reshape((1, nlinhas, ncolunas, 1), order='C')\n",
    "#                 x_data = np.concatenate([x_data, x_data_slice_reshape]) \n",
    "#                 y_data[i] = sim_status.iloc[j,0]\n",
    "\n",
    "#             x_data = x_data[1:, :] # Remove o primeiro array referente ao np.empty inicial\n",
    "#             x_windows = np.concatenate([x_windows, x_data])\n",
    "#             y_windows = np.append(y_windows, y_data)        \n",
    "\n",
    "#     x_windows = x_windows[1:, :] # Remove o primeiro array referente ao np.empty inicial\n",
    "    \n",
    "#     # Quando nem todos os STATUS estão presentes no banco, 'get_dummies' é uma alternativa\n",
    "#     y_windows_df = pd.DataFrame(y_windows).astype('category')\n",
    "#     y_windows_df_ohe = pd.get_dummies(y_windows_df)\n",
    "#     y_windows_ohe = y_windows_df_ohe.values\n",
    "    \n",
    "#     return x_windows, y_windows, y_windows_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
