{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import Counter\n",
    "from scipy import interp\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Dropout, MaxPooling2D, BatchNormalization, Activation, Flatten, GaussianNoise\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential, load_model, model_from_json\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV, ParameterGrid, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support , roc_auc_score, auc, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from pickle import load\n",
    "from timeit import default_timer as timer\n",
    "from random import randint\n",
    "from itertools import cycle\n",
    "\n",
    "%run ./base_functions.ipynb\n",
    "# %run ./config.ipynb\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_built_with_cuda()\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixando a seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value = randint(0, 99999)\n",
    "print(seed_value)\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parâmetros e configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição dos caminhos das pastas\n",
    "\n",
    "data_folder = \"D:\\\\TEP - Matlab\\\\\"\n",
    "outputs_folder = \"C:\\\\Users\\\\anaso\\\\Desktop\\\\workspace\\\\doutorado\\\\outputs\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CODE = 'PS8new-TF1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_stride_ana(array, max_time, sub_window_size, stride_size):\n",
    "    \n",
    "    sub_windows = ( \n",
    "        np.expand_dims(np.arange(sub_window_size), 0) +\n",
    "        np.expand_dims(np.arange(max_time + 1), 0).T\n",
    "    )\n",
    "    \n",
    "    # Descobre o index da última coluna do array\n",
    "    last_col_index = (array.shape[1])-1\n",
    "    \n",
    "    # Linha da matriz de índices que vai até o tamanho total do trecho que será convertido em matrizes\n",
    "    cut_point = np.where(sub_windows[:,last_col_index] == len(array)-1)[0].item()\n",
    "    \n",
    "    # Faz o corte\n",
    "    sub_windows_new = sub_windows[:cut_point+1] # adicionei o +1 pra bater com o número total de matreizes\n",
    "    \n",
    "    # Fancy indexing to select every V rows.\n",
    "    return array[sub_windows_new[::stride_size]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_folder + \"10-matlab-dados-3anos.csv\", sep=';')\n",
    "data_total = data.drop(['Unnamed: 0', 'XMV(12)'], 1)\n",
    "np.shape(data_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = pd.read_csv(data_folder + \"10-params-3anos.csv\", sep=';')\n",
    "sim_status = status.drop(['Unnamed: 0'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corte nos dados para reduzir o tamanho do banco\n",
    "\n",
    "data_treino = data_total.iloc[219285:270208,:]\n",
    "sim_status_treino = sim_status.iloc[320:390,:]\n",
    "\n",
    "data_teste = data_total.iloc[309787:395492,:]\n",
    "sim_status_teste = sim_status.iloc[450:580,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_treino.shape)\n",
    "print(data_teste.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlinhas = 52\n",
    "ncolunas = 52\n",
    "sliding_window = 5\n",
    "\n",
    "ti = timer()\n",
    "\n",
    "x_windows, y_windows, y_windows_ohe = matrix_generator(data_treino, sim_status_treino, nlinhas, ncolunas, sliding_window)\n",
    "\n",
    "tf = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tempo total: \" + str(int((tf-ti)//60)) + \" minutos e \" + str(math.ceil((tf-ti)%60))+ \" segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão randômica e estratificada em treino e validação\n",
    "\n",
    "X_train, X_valid, y_train_multi, y_valid_multi = train_test_split(x_windows, y_windows, \n",
    "                                                                  test_size=0.15, \n",
    "                                                                  random_state=seed_value, \n",
    "                                                                  shuffle=True, \n",
    "                                                                  stratify=y_windows)\n",
    "\n",
    "print(\"\\nTREINO\")\n",
    "print(\"X: \", np.shape(X_train))\n",
    "print(\"Y: \", np.shape(y_train_multi))\n",
    "print(\"Status:\", Counter(y_train_multi))\n",
    "\n",
    "print(\"\\nVALIDAÇÃO\")\n",
    "print(\"X: \", np.shape(X_valid))\n",
    "print(\"Y: \", np.shape(y_valid_multi))\n",
    "print(\"Status:\", Counter(y_valid_multi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATUS = np.unique(y_train_multi)\n",
    "\n",
    "# Faz um novo OHE\n",
    "y_windows_train_ohe = to_categorical(y_train_multi, num_classes=len(STATUS))\n",
    "y_windows_valid_ohe = to_categorical(y_valid_multi, num_classes=len(STATUS))\n",
    "\n",
    "y_train = y_windows_train_ohe\n",
    "y_valid = y_windows_valid_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "\n",
    "df_train = pd.DataFrame(X_train.reshape((nlinhas*X_train.shape[0], nlinhas)))\n",
    "df_valid = pd.DataFrame(X_valid.reshape((nlinhas*X_valid.shape[0], nlinhas)))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df_train)\n",
    "\n",
    "df_train_norm = scaler.transform(df_train)\n",
    "df_valid_norm = scaler.transform(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_to_4d_train = vectorized_stride_ana(df_train_norm, len(df_train_norm)-1, nlinhas, nlinhas)\n",
    "x_train = back_to_4d_train.reshape((len(back_to_4d_train), nlinhas, ncolunas, 1), order='C')\n",
    "\n",
    "back_to_4d_valid = vectorized_stride_ana(df_valid_norm, len(df_valid_norm)-1, nlinhas, nlinhas)\n",
    "x_valid = back_to_4d_valid.reshape((len(back_to_4d_valid), nlinhas, ncolunas, 1), order='C')\n",
    "\n",
    "print(X_train.shape)\n",
    "print(x_train.shape)\n",
    "print()\n",
    "\n",
    "print(X_valid.shape)\n",
    "print(x_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste sem shuffle\n",
    "\n",
    "# Scaling de acordo com o treino\n",
    "extra_test_norm = pd.DataFrame(scaler.transform(data_teste), columns=data_teste.columns)\n",
    "\n",
    "# Geração das matrizes\n",
    "x_test, y_windows, y_windows_ohe = matrix_generator(extra_test_norm, sim_status_teste, nlinhas, ncolunas, \\\n",
    "                                                    sliding_window)\n",
    "\n",
    "print()\n",
    "print(x_test.shape)\n",
    "print(Counter(y_windows))\n",
    "\n",
    "y_test = to_categorical(y_windows, num_classes=len(STATUS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem do sistema de FDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de class_weight para o caso multilabel\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', \n",
    "                                                  classes=np.unique(y_train.argmax(axis=1)), \n",
    "                                                  y=y_train.argmax(axis=1))\n",
    "\n",
    "class_weight_dict = {}\n",
    "for i in range(len(STATUS)):\n",
    "        class_weight_dict[i] = class_weights[i]\n",
    "\n",
    "class_weight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload do modelo original\n",
    "\n",
    "SOURCE_TEST_CODE = 'TS1'\n",
    "training_type = \"simple_model_\"\n",
    "\n",
    "if (training_type == \"optuna_model_\"):\n",
    "    trial = 20\n",
    "    json_file = open(outputs_folder + training_type + SOURCE_TEST_CODE + \"_\" + str(trial) + '-CNN.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    model.load_weights(outputs_folder + training_type + SOURCE_TEST_CODE + \"_\" + str(trial) + \"-CNN.h5\")\n",
    "else:\n",
    "    json_file = open(outputs_folder + training_type + SOURCE_TEST_CODE + '-CNN.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    model.load_weights(outputs_folder + training_type + SOURCE_TEST_CODE + \"-CNN.h5\")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.001), \\\n",
    "                  metrics=['acc', Precision(), Recall()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tranfer learning - Treino simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Cria um novo modelo sequencial \n",
    "\n",
    "new_model = Sequential()\n",
    "\n",
    "for layer in model.layers[:-1]:     #extrai cada uma das camadas do modelo original\n",
    "    new_model.add(layer)            #adiciona no modelo criado até a penultima camada\n",
    "\n",
    "# Colocando as camadas intermediárias em modo de \"hibernação\"\n",
    "# Colocar em modo de hibernação, garante que, durante o treinamento, os pesos não serão atualizados\n",
    "for layer in new_model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adiciona as últimas camadas que farão a classificação das falhas para passarem pelo fine tunning \n",
    "\n",
    "new_model.add(Dense(len(STATUS), activation='softmax'))\n",
    "\n",
    "# Mostra o novo modelo CNN\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Treinamento da rede convolucional\n",
    "\n",
    "# Definição dos callbacks usados\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='auto', patience=20, restore_best_weights=True)\n",
    "model_check = ModelCheckpoint(filepath=outputs_folder+\"model_cp_\"+TEST_CODE+\".h5\", monitor=\"val_loss\", mode=\"auto\")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.0001), \n",
    "              metrics=['acc', Precision(), Recall()])\n",
    "\n",
    "ti = timer()\n",
    "\n",
    "history = model.fit(x_train, y_train, \n",
    "                    epochs=100, \n",
    "                    batch_size=500, \n",
    "                    validation_data=(x_valid, y_valid), \n",
    "                    verbose=1,\n",
    "                    shuffle=False,\n",
    "                    class_weight=class_weight_dict,\n",
    "                    callbacks=[early_stopping, model_check]) \n",
    "\n",
    "save_model(model=model, iterator=TEST_CODE, train_type='simple', model_name='CNN')\n",
    "\n",
    "tf = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tempo total: \" + str(int((tf-ti)//60)) + \" minutos e \" + str(math.ceil((tf-ti)%60))+ \" segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Gráficos - Treinamento x Validação\n",
    "\n",
    "# Informações do treinamento\n",
    "try:\n",
    "    train_acc = history.history[model.metrics_names[1]]\n",
    "    train_loss = history.history[model.metrics_names[0]]\n",
    "    train_precision = history.history[model.metrics_names[2]]\n",
    "    train_recall = history.history[model.metrics_names[3]]\n",
    "except:\n",
    "    # quando o history vem do CSV salvo do melhor modelo\n",
    "    train_acc = history['acc']\n",
    "    train_loss = history['loss']\n",
    "    train_precision = history['precision_'+str(best_trial)]\n",
    "    train_recall = history['recall_'+str(best_trial)]\n",
    "\n",
    "# Informações da validação\n",
    "try:\n",
    "    val_acc = history.history['val_'+str(model.metrics_names[1])]\n",
    "    val_loss = history.history['val_'+str(model.metrics_names[0])]\n",
    "    val_precision = history.history['val_'+str(model.metrics_names[2])]\n",
    "    val_recall = history.history['val_'+str(model.metrics_names[3])]\n",
    "except:\n",
    "    val_acc = history['val_acc']\n",
    "    val_loss = history['val_loss']\n",
    "    val_precision = history['val_precision_'+str(best_trial)]\n",
    "    val_recall = history['val_recall_'+str(best_trial)]\n",
    "\n",
    "epochs = range(1, len(train_acc) + 1)\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "print(\"Épocas: \", len(epochs))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs, train_acc, '-bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, '-ko', label='Validation acc')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs, train_loss, '-bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, '-ko', label='Validation loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(epochs, train_precision, '-bo', label='Training precision')\n",
    "plt.plot(epochs, val_precision, '-ko', label='Validation precision')\n",
    "plt.title('Precision')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(epochs, train_recall, '-bo', label='Training recall')\n",
    "plt.plot(epochs, val_recall, '-ko', label='Validation recall')\n",
    "plt.title('Recall')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento\n",
    "\n",
    "train_metrics = display_metrics(x_train, y_train, model, STATUS, 'Treino', multi_problem=True) \n",
    "train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Validação\n",
    "\n",
    "valid_metrics = display_metrics(x_valid, y_valid, model, STATUS, 'Validação', multi_problem=True) \n",
    "valid_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Teste\n",
    "\n",
    "test_metrics = display_metrics(x_test, y_test, model, STATUS, 'Teste', multi_problem=True) \n",
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construção da curva ROC para o caso binário (base: classe 0)\n",
    "\n",
    "model_pred = model.predict(x_test)\n",
    "\n",
    "# Dados reais em OHE\n",
    "y_test = y_test.copy()\n",
    "\n",
    "# Predições em OHE\n",
    "y_pred = pd.DataFrame(model_pred.argmax(axis=1)).astype('category')\n",
    "y_pred = pd.get_dummies(y_pred).values\n",
    "\n",
    "n_classes = len(STATUS)\n",
    "\n",
    "# Calcula a curva ROC e a métrica AUC para cada classe\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i], )\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "plt.figure(figsize=(5,5), dpi=300)\n",
    "plt.plot(fpr[0], tpr[0], color='darkorange', lw=2, label='Curva ROC (area = %0.3f)' % roc_auc[0])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de falsos positivos')\n",
    "plt.ylabel('Taxa de verdadeiros positivos')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC e cálculo da métrica AUC para todas as classes\n",
    "\n",
    "roc_auc_scores = []\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(12,12), dpi=300)\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"], label='micro-average ROC curve (area = {0:0.3f})'''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"], label='macro-average ROC curve (area = {0:0.3f})'''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2, label='ROC curve of class {0} (area = {1:0.3f})'''.format(i, roc_auc[i]))\n",
    "    roc_auc_scores.append(roc_auc[i])\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de falsos positivos')\n",
    "plt.ylabel('Taxa de verdadeiros positivos')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
